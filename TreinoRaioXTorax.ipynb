{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TreinoRaioXTorax.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iTe-94FXjok9",
        "M72QrYq7m1U7",
        "tXEayPhroBV5",
        "GQa14QElVuRx",
        "BWZdaCswKOmm"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ett16DjnF9R",
        "colab_type": "text"
      },
      "source": [
        "# Notebook criado para treino de CNN para predição de classes Raio-x ou Não Raio-x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y30J8pja6lPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfKV81QoGyo",
        "colab_type": "text"
      },
      "source": [
        "#### Tutorial utilizado: https://towardsdatascience.com/train-image-recognition-ai-with-5-lines-of-code-8ed0bdd8d9ba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTKw0QRSmoCp",
        "colab_type": "text"
      },
      "source": [
        "# Instalação do ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ZXB8Nt27qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_-c9_zZeqEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow==1.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIDSKm-aq035",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Tq3m0Lea77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrTmlmjHegMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8RF65RCmr9N",
        "colab_type": "text"
      },
      "source": [
        "# Treino do zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD4pI7TkeUM5",
        "colab_type": "code",
        "outputId": "0e5dcc98-96a0-488d-c028-600be013ee10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from imageai.Prediction.Custom import ModelTraining\n",
        "\n",
        "model_trainer = ModelTraining()\n",
        "model_trainer.setModelTypeAsInceptionV3()\n",
        "model_trainer.setDataDirectory(\"/content/drive/My Drive/Thorax-XRay-Dataset-v2\")\n",
        "model_trainer.trainModel(num_objects=2, num_experiments=100, enhance_data=True, batch_size=4, show_network_summary=True, save_full_model=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 21,806,882\n",
            "Trainable params: 21,772,450\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
            "Using Enhanced Data Generation\n",
            "Found 887 images belonging to 2 classes.\n",
            "Found 167 images belonging to 2 classes.\n",
            "JSON Mapping for the model classes saved to  /content/drive/My Drive/Thorax-XRay-Dataset-v2/json/model_class.json\n",
            "Number of experiments (Epochs) :  100\n",
            "Epoch 1/100\n",
            "220/221 [============================>.] - ETA: 2s - loss: 0.7604 - acc: 0.7008Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 10:08 - loss: 1.1404 - acc: 0.7988\n",
            "Epoch 00001: val_acc improved from -inf to 0.79878, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-001_acc-0.798781.h5\n",
            "221/221 [==============================] - 827s 4s/step - loss: 0.7577 - acc: 0.7022 - val_loss: 1.1404 - val_acc: 0.7988\n",
            "Epoch 2/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8100Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.5272 - acc: 0.9062\n",
            "Epoch 00002: val_acc improved from 0.79878 to 0.90244, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-002_acc-0.902439.h5\n",
            "221/221 [==============================] - 35s 159ms/step - loss: 0.4830 - acc: 0.8097 - val_loss: 0.5237 - val_acc: 0.9024\n",
            "Epoch 3/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.8339Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 2.6125 - acc: 0.8188\n",
            "Epoch 00003: val_acc did not improve from 0.90244\n",
            "221/221 [==============================] - 33s 149ms/step - loss: 0.4459 - acc: 0.8347 - val_loss: 2.5856 - val_acc: 0.8171\n",
            "Epoch 4/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.4392 - acc: 0.8476Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.1144 - acc: 0.9750\n",
            "Epoch 00004: val_acc improved from 0.90244 to 0.96951, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-004_acc-0.969512.h5\n",
            "221/221 [==============================] - 33s 150ms/step - loss: 0.4391 - acc: 0.8471 - val_loss: 0.1250 - val_acc: 0.9695\n",
            "Epoch 5/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.8828Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 1.5360 - acc: 0.5000\n",
            "Epoch 00005: val_acc did not improve from 0.96951\n",
            "221/221 [==============================] - 32s 146ms/step - loss: 0.3231 - acc: 0.8834 - val_loss: 1.5322 - val_acc: 0.5000\n",
            "Epoch 6/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.3142 - acc: 0.8966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 1.5997 - acc: 0.5000\n",
            "Epoch 00006: val_acc did not improve from 0.96951\n",
            "221/221 [==============================] - 32s 144ms/step - loss: 0.3186 - acc: 0.8959 - val_loss: 1.5982 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9089Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0656 - acc: 0.9875\n",
            "Epoch 00007: val_acc improved from 0.96951 to 0.98780, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-007_acc-0.987805.h5\n",
            "221/221 [==============================] - 33s 151ms/step - loss: 0.2888 - acc: 0.9093 - val_loss: 0.0648 - val_acc: 0.9878\n",
            "Epoch 8/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2729 - acc: 0.9192Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.1007 - acc: 0.9812\n",
            "Epoch 00008: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 32s 145ms/step - loss: 0.2719 - acc: 0.9196 - val_loss: 0.1023 - val_acc: 0.9817\n",
            "Epoch 9/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9215Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0997 - acc: 0.9688\n",
            "Epoch 00009: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 32s 144ms/step - loss: 0.2596 - acc: 0.9219 - val_loss: 0.1009 - val_acc: 0.9695\n",
            "Epoch 10/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.9022Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.3849 - acc: 0.7866\n",
            "Epoch 00010: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 32s 143ms/step - loss: 0.3153 - acc: 0.9026 - val_loss: 0.3849 - val_acc: 0.7866\n",
            "Epoch 11/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9261Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 1.0108 - acc: 0.5793\n",
            "Epoch 00011: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 31s 141ms/step - loss: 0.1983 - acc: 0.9264 - val_loss: 1.0108 - val_acc: 0.5793\n",
            "Epoch 12/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9226Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 10s - loss: 0.1469 - acc: 0.9390\n",
            "Epoch 00012: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 32s 145ms/step - loss: 0.2027 - acc: 0.9230 - val_loss: 0.1469 - val_acc: 0.9390\n",
            "Epoch 13/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9158Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.1178 - acc: 0.9438\n",
            "Epoch 00013: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 31s 142ms/step - loss: 0.2298 - acc: 0.9151 - val_loss: 0.1172 - val_acc: 0.9451\n",
            "Epoch 14/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9204Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0980 - acc: 0.9625\n",
            "Epoch 00014: val_acc did not improve from 0.98780\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.2203 - acc: 0.9207 - val_loss: 0.0963 - val_acc: 0.9634\n",
            "Epoch 15/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9397Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0244 - acc: 0.9937\n",
            "Epoch 00015: val_acc improved from 0.98780 to 0.99390, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-015_acc-0.993902.h5\n",
            "221/221 [==============================] - 33s 148ms/step - loss: 0.1713 - acc: 0.9400 - val_loss: 0.0240 - val_acc: 0.9939\n",
            "Epoch 16/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9408Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 1.9181 - acc: 0.5061\n",
            "Epoch 00016: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 142ms/step - loss: 0.1817 - acc: 0.9400 - val_loss: 1.9181 - val_acc: 0.5061\n",
            "Epoch 17/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9306Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 2.8640 - acc: 0.4938\n",
            "Epoch 00017: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 141ms/step - loss: 0.1798 - acc: 0.9298 - val_loss: 2.8565 - val_acc: 0.4939\n",
            "Epoch 18/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9283Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0922 - acc: 0.9875\n",
            "Epoch 00018: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.1878 - acc: 0.9275 - val_loss: 0.0963 - val_acc: 0.9878\n",
            "Epoch 19/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9408Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 2.2007 - acc: 0.5000\n",
            "Epoch 00019: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.1475 - acc: 0.9411 - val_loss: 2.1991 - val_acc: 0.5000\n",
            "Epoch 20/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9443Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.2062 - acc: 0.9250\n",
            "Epoch 00020: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.1648 - acc: 0.9445 - val_loss: 0.2031 - val_acc: 0.9268\n",
            "Epoch 21/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9465Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0571 - acc: 0.9812\n",
            "Epoch 00021: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.1472 - acc: 0.9468 - val_loss: 0.0561 - val_acc: 0.9817\n",
            "Epoch 22/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9545Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 10s - loss: 0.9128 - acc: 0.5625\n",
            "Epoch 00022: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 142ms/step - loss: 0.1229 - acc: 0.9547 - val_loss: 0.9140 - val_acc: 0.5610\n",
            "Epoch 23/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9465Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0533 - acc: 0.9812\n",
            "Epoch 00023: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.1696 - acc: 0.9468 - val_loss: 0.0529 - val_acc: 0.9817\n",
            "Epoch 24/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9556Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 1.9202 - acc: 0.5375\n",
            "Epoch 00024: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.1465 - acc: 0.9558 - val_loss: 1.9354 - val_acc: 0.5366\n",
            "Epoch 25/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9534Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.7729 - acc: 0.7937\n",
            "Epoch 00025: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.1312 - acc: 0.9536 - val_loss: 0.8101 - val_acc: 0.7866\n",
            "Epoch 26/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9636Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.3221 - acc: 0.8687\n",
            "Epoch 00026: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.1119 - acc: 0.9638 - val_loss: 0.3164 - val_acc: 0.8720\n",
            "Epoch 27/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9556Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 1.5528 - acc: 0.5000\n",
            "Epoch 00027: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 138ms/step - loss: 0.1480 - acc: 0.9547 - val_loss: 1.5715 - val_acc: 0.5000\n",
            "Epoch 28/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9579Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.6877 - acc: 0.7125\n",
            "Epoch 00028: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.1400 - acc: 0.9581 - val_loss: 0.6998 - val_acc: 0.7073\n",
            "Epoch 29/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9500Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.1015 - acc: 0.9563\n",
            "Epoch 00029: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.1306 - acc: 0.9502 - val_loss: 0.1105 - val_acc: 0.9512\n",
            "Epoch 30/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9579Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.1358 - acc: 0.9438\n",
            "Epoch 00030: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 138ms/step - loss: 0.1241 - acc: 0.9580 - val_loss: 0.1329 - val_acc: 0.9451\n",
            "Epoch 31/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9522Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.3902 - acc: 0.7875\n",
            "Epoch 00031: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.1221 - acc: 0.9524 - val_loss: 0.3812 - val_acc: 0.7927\n",
            "Epoch 32/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9659Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0194 - acc: 0.9939\n",
            "Epoch 00032: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0883 - acc: 0.9660 - val_loss: 0.0194 - val_acc: 0.9939\n",
            "Epoch 33/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9591Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0883 - acc: 0.9563\n",
            "Epoch 00033: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.1100 - acc: 0.9581 - val_loss: 0.0897 - val_acc: 0.9573\n",
            "Epoch 34/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9681Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0339 - acc: 0.9937\n",
            "Epoch 00034: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.0893 - acc: 0.9683 - val_loss: 0.0362 - val_acc: 0.9939\n",
            "Epoch 35/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9659Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0203 - acc: 0.9875\n",
            "Epoch 00035: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0754 - acc: 0.9660 - val_loss: 0.0198 - val_acc: 0.9878\n",
            "Epoch 36/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9625Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0320 - acc: 0.9937\n",
            "Epoch 00036: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.1092 - acc: 0.9626 - val_loss: 0.0319 - val_acc: 0.9939\n",
            "Epoch 37/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9818Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0221 - acc: 0.9937\n",
            "Epoch 00037: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0592 - acc: 0.9819 - val_loss: 0.0217 - val_acc: 0.9939\n",
            "Epoch 38/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9670Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0241 - acc: 0.9937\n",
            "Epoch 00038: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 133ms/step - loss: 0.1067 - acc: 0.9672 - val_loss: 0.0236 - val_acc: 0.9939\n",
            "Epoch 39/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9704Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0536 - acc: 0.9812\n",
            "Epoch 00039: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0951 - acc: 0.9694 - val_loss: 0.0525 - val_acc: 0.9817\n",
            "Epoch 40/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9681Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0151 - acc: 0.9939\n",
            "Epoch 00040: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 133ms/step - loss: 0.0854 - acc: 0.9683 - val_loss: 0.0151 - val_acc: 0.9939\n",
            "Epoch 41/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9659Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 1.9595 - acc: 0.5250\n",
            "Epoch 00041: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0872 - acc: 0.9660 - val_loss: 1.9830 - val_acc: 0.5244\n",
            "Epoch 42/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9807Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0309 - acc: 0.9875\n",
            "Epoch 00042: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0516 - acc: 0.9807 - val_loss: 0.0305 - val_acc: 0.9878\n",
            "Epoch 43/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9875Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0240 - acc: 0.9875\n",
            "Epoch 00043: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 133ms/step - loss: 0.0361 - acc: 0.9875 - val_loss: 0.0236 - val_acc: 0.9878\n",
            "Epoch 44/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9875Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0241 - acc: 0.9812\n",
            "Epoch 00044: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 138ms/step - loss: 0.0409 - acc: 0.9876 - val_loss: 0.0237 - val_acc: 0.9817\n",
            "Epoch 45/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9806Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0288 - acc: 0.9937\n",
            "Epoch 00045: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0587 - acc: 0.9807 - val_loss: 0.0282 - val_acc: 0.9939\n",
            "Epoch 46/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9955Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0193 - acc: 0.9937\n",
            "Epoch 00046: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 132ms/step - loss: 0.0261 - acc: 0.9955 - val_loss: 0.0189 - val_acc: 0.9939\n",
            "Epoch 47/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9886Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0168 - acc: 0.9939\n",
            "Epoch 00047: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 131ms/step - loss: 0.0272 - acc: 0.9887 - val_loss: 0.0168 - val_acc: 0.9939\n",
            "Epoch 48/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9841Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0234 - acc: 0.9937\n",
            "Epoch 00048: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.0536 - acc: 0.9841 - val_loss: 0.0229 - val_acc: 0.9939\n",
            "Epoch 49/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9898Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0235 - acc: 0.9878\n",
            "Epoch 00049: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 132ms/step - loss: 0.0359 - acc: 0.9898 - val_loss: 0.0235 - val_acc: 0.9878\n",
            "Epoch 50/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0164 - acc: 0.9937\n",
            "Epoch 00050: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0302 - acc: 0.9909 - val_loss: 0.0160 - val_acc: 0.9939\n",
            "Epoch 51/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0181 - acc: 0.9937\n",
            "Epoch 00051: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0244 - acc: 0.9943 - val_loss: 0.0177 - val_acc: 0.9939\n",
            "Epoch 52/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0119 - acc: 0.9937\n",
            "Epoch 00052: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 31s 141ms/step - loss: 0.0164 - acc: 0.9966 - val_loss: 0.0116 - val_acc: 0.9939\n",
            "Epoch 53/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9863Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0135 - acc: 0.9937\n",
            "Epoch 00053: val_acc did not improve from 0.99390\n",
            "221/221 [==============================] - 29s 130ms/step - loss: 0.0456 - acc: 0.9864 - val_loss: 0.0132 - val_acc: 0.9939\n",
            "Epoch 54/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 00054: val_acc improved from 0.99390 to 1.00000, saving model to /content/drive/My Drive/Thorax-XRay-Dataset-v2/models/model_ex-054_acc-1.000000.h5\n",
            "221/221 [==============================] - 32s 146ms/step - loss: 0.0250 - acc: 0.9932 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 00055: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0426 - acc: 0.9910 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0164 - acc: 0.9937\n",
            "Epoch 00056: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0259 - acc: 0.9943 - val_loss: 0.0161 - val_acc: 0.9939\n",
            "Epoch 57/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 00057: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 138ms/step - loss: 0.0229 - acc: 0.9909 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9955Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0118 - acc: 0.9939\n",
            "Epoch 00058: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0252 - acc: 0.9955 - val_loss: 0.0118 - val_acc: 0.9939\n",
            "Epoch 59/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0148 - acc: 0.9937\n",
            "Epoch 00059: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 133ms/step - loss: 0.0232 - acc: 0.9932 - val_loss: 0.0144 - val_acc: 0.9939\n",
            "Epoch 60/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9920Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0181 - acc: 0.9875\n",
            "Epoch 00060: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 32s 143ms/step - loss: 0.0227 - acc: 0.9921 - val_loss: 0.0176 - val_acc: 0.9878\n",
            "Epoch 61/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0140 - acc: 0.9937\n",
            "Epoch 00061: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0137 - val_acc: 0.9939\n",
            "Epoch 62/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0143 - acc: 0.9937\n",
            "Epoch 00062: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0167 - acc: 0.9966 - val_loss: 0.0139 - val_acc: 0.9939\n",
            "Epoch 63/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 10s - loss: 0.0160 - acc: 0.9937\n",
            "Epoch 00063: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 138ms/step - loss: 0.0202 - acc: 0.9943 - val_loss: 0.0157 - val_acc: 0.9939\n",
            "Epoch 64/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0184 - acc: 0.9875\n",
            "Epoch 00064: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.0270 - acc: 0.9909 - val_loss: 0.0180 - val_acc: 0.9878\n",
            "Epoch 65/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0174 - acc: 0.9875\n",
            "Epoch 00065: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.0149 - acc: 0.9966 - val_loss: 0.0170 - val_acc: 0.9878\n",
            "Epoch 66/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0170 - acc: 0.9875\n",
            "Epoch 00066: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 129ms/step - loss: 0.0140 - acc: 0.9943 - val_loss: 0.0166 - val_acc: 0.9878\n",
            "Epoch 67/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0178 - acc: 0.9875\n",
            "Epoch 00067: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 138ms/step - loss: 0.0273 - acc: 0.9932 - val_loss: 0.0174 - val_acc: 0.9878\n",
            "Epoch 68/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9920Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0196 - acc: 0.9875\n",
            "Epoch 00068: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.0262 - acc: 0.9921 - val_loss: 0.0191 - val_acc: 0.9878\n",
            "Epoch 69/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9989Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0183 - acc: 0.9875\n",
            "Epoch 00069: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 141ms/step - loss: 0.0089 - acc: 0.9989 - val_loss: 0.0179 - val_acc: 0.9878\n",
            "Epoch 70/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9977Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0194 - acc: 0.9875\n",
            "Epoch 00070: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 138ms/step - loss: 0.0185 - acc: 0.9977 - val_loss: 0.0189 - val_acc: 0.9878\n",
            "Epoch 71/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0195 - acc: 0.9875\n",
            "Epoch 00071: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 132ms/step - loss: 0.0304 - acc: 0.9898 - val_loss: 0.0191 - val_acc: 0.9878\n",
            "Epoch 72/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9955Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0199 - acc: 0.9875\n",
            "Epoch 00072: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0188 - acc: 0.9955 - val_loss: 0.0194 - val_acc: 0.9878\n",
            "Epoch 73/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9977Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0216 - acc: 0.9875\n",
            "Epoch 00073: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 131ms/step - loss: 0.0130 - acc: 0.9977 - val_loss: 0.0211 - val_acc: 0.9878\n",
            "Epoch 74/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9977Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0193 - acc: 0.9875\n",
            "Epoch 00074: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 140ms/step - loss: 0.0140 - acc: 0.9977 - val_loss: 0.0189 - val_acc: 0.9878\n",
            "Epoch 75/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0189 - acc: 0.9875\n",
            "Epoch 00075: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.0173 - acc: 0.9966 - val_loss: 0.0184 - val_acc: 0.9878\n",
            "Epoch 76/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9954Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0185 - acc: 0.9875\n",
            "Epoch 00076: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 133ms/step - loss: 0.0173 - acc: 0.9955 - val_loss: 0.0181 - val_acc: 0.9878\n",
            "Epoch 77/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0177 - acc: 0.9875\n",
            "Epoch 00077: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0173 - val_acc: 0.9878\n",
            "Epoch 78/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0184 - acc: 0.9875\n",
            "Epoch 00078: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.0180 - val_acc: 0.9878\n",
            "Epoch 79/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0198 - acc: 0.9875\n",
            "Epoch 00079: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0194 - val_acc: 0.9878\n",
            "Epoch 80/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0198 - acc: 0.9875\n",
            "Epoch 00080: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 130ms/step - loss: 0.0185 - acc: 0.9955 - val_loss: 0.0193 - val_acc: 0.9878\n",
            "Epoch 81/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9932Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0190 - acc: 0.9878\n",
            "Epoch 00081: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 141ms/step - loss: 0.0190 - acc: 0.9932 - val_loss: 0.0190 - val_acc: 0.9878\n",
            "Epoch 82/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0194 - acc: 0.9875\n",
            "Epoch 00082: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 131ms/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.0190 - val_acc: 0.9878\n",
            "Epoch 83/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9954Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 8s - loss: 0.0192 - acc: 0.9878\n",
            "Epoch 00083: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0186 - acc: 0.9955 - val_loss: 0.0192 - val_acc: 0.9878\n",
            "Epoch 84/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0178 - acc: 0.9875\n",
            "Epoch 00084: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 142ms/step - loss: 0.0202 - acc: 0.9932 - val_loss: 0.0174 - val_acc: 0.9878\n",
            "Epoch 85/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9989Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0183 - acc: 0.9875\n",
            "Epoch 00085: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0105 - acc: 0.9977 - val_loss: 0.0179 - val_acc: 0.9878\n",
            "Epoch 86/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9954Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0187 - acc: 0.9875\n",
            "Epoch 00086: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.0224 - acc: 0.9955 - val_loss: 0.0183 - val_acc: 0.9878\n",
            "Epoch 87/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9989Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0192 - acc: 0.9875\n",
            "Epoch 00087: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 133ms/step - loss: 0.0121 - acc: 0.9989 - val_loss: 0.0187 - val_acc: 0.9878\n",
            "Epoch 88/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0198 - acc: 0.9875\n",
            "Epoch 00088: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 136ms/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0194 - val_acc: 0.9878\n",
            "Epoch 89/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9954Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0200 - acc: 0.9875\n",
            "Epoch 00089: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0200 - acc: 0.9955 - val_loss: 0.0196 - val_acc: 0.9878\n",
            "Epoch 90/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9966Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0208 - acc: 0.9875\n",
            "Epoch 00090: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0160 - acc: 0.9966 - val_loss: 0.0203 - val_acc: 0.9878\n",
            "Epoch 91/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0199 - acc: 0.9875\n",
            "Epoch 00091: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0227 - acc: 0.9943 - val_loss: 0.0194 - val_acc: 0.9878\n",
            "Epoch 92/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9989Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0197 - acc: 0.9875\n",
            "Epoch 00092: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0155 - acc: 0.9977 - val_loss: 0.0192 - val_acc: 0.9878\n",
            "Epoch 93/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9909Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0193 - acc: 0.9875\n",
            "Epoch 00093: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 135ms/step - loss: 0.0218 - acc: 0.9909 - val_loss: 0.0188 - val_acc: 0.9878\n",
            "Epoch 94/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9920Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0190 - acc: 0.9875\n",
            "Epoch 00094: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 138ms/step - loss: 0.0281 - acc: 0.9921 - val_loss: 0.0186 - val_acc: 0.9878\n",
            "Epoch 95/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9898Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 8s - loss: 0.0182 - acc: 0.9875\n",
            "Epoch 00095: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 28s 127ms/step - loss: 0.0253 - acc: 0.9898 - val_loss: 0.0178 - val_acc: 0.9878\n",
            "Epoch 96/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9966Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0192 - acc: 0.9878\n",
            "Epoch 00096: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 137ms/step - loss: 0.0176 - acc: 0.9966 - val_loss: 0.0192 - val_acc: 0.9878\n",
            "Epoch 97/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9943Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0202 - acc: 0.9875\n",
            "Epoch 00097: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 31s 139ms/step - loss: 0.0216 - acc: 0.9943 - val_loss: 0.0198 - val_acc: 0.9878\n",
            "Epoch 98/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9932Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0202 - acc: 0.9875\n",
            "Epoch 00098: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 131ms/step - loss: 0.0244 - acc: 0.9932 - val_loss: 0.0197 - val_acc: 0.9878\n",
            "Epoch 99/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9977Epoch 1/100\n",
            " 40/221 [====>.........................] - ETA: 9s - loss: 0.0200 - acc: 0.9875\n",
            "Epoch 00099: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 29s 131ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.0195 - val_acc: 0.9878\n",
            "Epoch 100/100\n",
            "220/221 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9966Epoch 1/100\n",
            " 41/221 [====>.........................] - ETA: 9s - loss: 0.0177 - acc: 0.9878\n",
            "Epoch 00100: val_acc did not improve from 1.00000\n",
            "221/221 [==============================] - 30s 134ms/step - loss: 0.0187 - acc: 0.9966 - val_loss: 0.0177 - val_acc: 0.9878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTe-94FXjok9",
        "colab_type": "text"
      },
      "source": [
        "# Treino continuando da 5ª época."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0s7JvYGmKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Prediction.Custom import ModelTraining\n",
        "\n",
        "model_trainer = ModelTraining()\n",
        "model_trainer.setModelTypeAsResNet()\n",
        "model_trainer.setDataDirectory(\"/content/drive/My Drive/Thorax-XRay-Dataset\")\n",
        "model_trainer.trainModel(num_objects=2, num_experiments=5, enhance_data=True, batch_size=4, show_network_summary=True, continue_from_model=\"/content/drive/My Drive/Thorax-XRay-Dataset/models/model_ex-003_acc-0.987342.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M72QrYq7m1U7",
        "colab_type": "text"
      },
      "source": [
        "# Compactação da Model para download a posteriori"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbmy4Vco3x47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r Thorax-XRay-Dataset.zip Thorax-XRay-Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXEayPhroBV5",
        "colab_type": "text"
      },
      "source": [
        "# Predição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k5nn9xbr9TP",
        "colab_type": "code",
        "outputId": "dc681c08-e0af-4167-f289-22f383c5a360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from imageai.Prediction.Custom import CustomImagePrediction\n",
        "import os\n",
        "\n",
        "execution_path = os.getcwd()\n",
        "\n",
        "prediction = CustomImagePrediction()\n",
        "prediction.setModelTypeAsResNet()\n",
        "prediction.setModelPath(os.path.join(execution_path, \"drive/My Drive/Thorax-XRay-Dataset/models/model_ex-003_acc-0.992405.h5\"))\n",
        "prediction.setJsonPath(os.path.join(execution_path, \"drive/My Drive/Thorax-XRay-Dataset/json/model_class.json\"))\n",
        "prediction.loadModel(num_objects=2)\n",
        "\n",
        "predictions, probabilities = prediction.predictImage(os.path.join(execution_path, \"raiox-maos.jpeg\"), result_count=2)\n",
        "\n",
        "for eachPrediction, eachProbability in zip(predictions, probabilities):\n",
        "    print(eachPrediction , \" : \" , eachProbability)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not-XRay-Thorax  :  64.29535150527954\n",
            "XRay-Thorax  :  35.70465445518494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQa14QElVuRx",
        "colab_type": "text"
      },
      "source": [
        "# Visualização de especificações de Hardware"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxH9m0pjV9Oe",
        "colab_type": "code",
        "outputId": "52d902f3-ff78-4aa4-cdba-bea05938c49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 973369867650267352, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 3744122538999160396\n",
              " physical_device_desc: \"device: XLA_CPU device\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrXACIsjW78K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqrwalrCXF3y",
        "colab_type": "code",
        "outputId": "73cb77c4-2b7f-4493-be38-5aa65f999bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.174\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4000.34\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.174\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4000.34\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "MemTotal:       13333556 kB\n",
            "MemFree:        10599020 kB\n",
            "MemAvailable:   12407432 kB\n",
            "Buffers:           70164 kB\n",
            "Cached:          1885676 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           816388 kB\n",
            "Inactive:        1666840 kB\n",
            "Active(anon):     495876 kB\n",
            "Inactive(anon):      312 kB\n",
            "Active(file):     320512 kB\n",
            "Inactive(file):  1666528 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               148 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        527488 kB\n",
            "Mapped:           338212 kB\n",
            "Shmem:               904 kB\n",
            "Slab:             161396 kB\n",
            "SReclaimable:     124532 kB\n",
            "SUnreclaim:        36864 kB\n",
            "KernelStack:        3488 kB\n",
            "PageTables:         6164 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6666776 kB\n",
            "Committed_AS:    2657492 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:              920 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:       76988 kB\n",
            "DirectMap2M:     5165056 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWZdaCswKOmm",
        "colab_type": "text"
      },
      "source": [
        "# Instalação do driver CUDA para treinar na GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epAZCd3_ZHke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.1.85-1_amd64.deb\n",
        "!apt install ./cuda-repo-ubuntu1604_9.1.85-1_amd64.deb\n",
        "!wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\n",
        "!apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\n",
        "!apt update\n",
        "\n",
        "# Install CUDA and tools. Include optional NCCL 2.x\n",
        "!apt install cuda9.0 cuda-cublas-9-0 cuda-cufft-9-0 cuda-curand-9-0 \\\n",
        "    cuda-cusolver-9-0 cuda-cusparse-9-0 libcudnn7=7.2.1.38-1+cuda9.0 \\\n",
        "    libnccl2=2.2.13-1+cuda9.0 cuda-command-line-tools-9-0\n",
        "\n",
        "# Optional: Install the TensorRT runtime (must be after CUDA install)\n",
        "!apt update\n",
        "!apt install libnvinfer4=4.1.2-1+cuda9.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgQ5mOmVJWzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}